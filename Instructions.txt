<<<<<<< branch-chandu
Hi, I am Chandu
=======
Hi I am Subhan Faisal


def display_resume():
    # Contact Information
    contact_info = {
        'Name': 'CHANDAR RATHALA',
        'Mobile': '+1 (813) 418-9804',
        'Email': 'chandarrathala9@gmail.com',
        'LinkedIn': 'linkedin.com/in/chandar-rathala'
    }

    # Education
    education = [
        {
            'degree': 'Masters in Business Analytics & Artificial Intelligence',
            'university': 'University of South Florida',
            'location': 'Tampa, FL',
            'dates': 'Aug 2024 - Present'
        },
        {
            'degree': 'Bachelors in Computer Science',
            'university': 'Jawaharlal Nehru Technological University',
            'location': 'Hyderabad, Telangana',
            'dates': 'Jun 2017 - Sep 2021'
        }
    ]

    # Skills
    skills = {
        'Programming Languages': ['JAVA', 'Python', 'R', 'Base SAS', 'Scala'],
        'Database & Big Data': ['MySQL', 'SQL Server', 'SQL', 'NoSQL', 'Oracle', 'Teradata', 
                               'AWS Redshift', 'Hadoop', 'Ab Initio', 'Snowflake DB'],
        'Web Development': ['HTML5', 'CSS3', 'JavaScript'],
        'Data Visualization & ETL': ['Tableau', 'Power BI', 'Informatica Power Center', 
                                    'Informatica Cloud', 'ETL techniques'],
        'Cloud & Version Control': ['AWS Redshift', 'GitHub', 'VersionOne', 'Jira'],
        'Analytics': ['Advanced Excel', 'VBA', 'Data Analysis', 'Statistical Management',
                     'Clinical Data Management', 'Financial Data Analysis', 'Requirement Analysis'],
        'Systems & Tools': ['Linux', 'SAS Studio', 'Bash Scripting', 'Docker',
                           'Kubernetes', 'Apache Airflow'],
        'Concepts': ['Statistics', 'Data Structures', 'Object Oriented Programming',
                    'Machine Learning Models', 'Business Intelligence']
    }

    # Experience
    experience = [
        {
            'position': 'Data Analyst',
            'company': 'DXC Technology',
            'location': 'India',
            'dates': 'Aug 2020 – Jul 2022',
            'responsibilities': [
                'Oversaw AWS Redshift migration, retiring SAS systems and implementing CI/CT/CD, boosting system reliability by 30% and operational efficiency by 40%',
                'Optimized 600+ SAS programs and migrated 1000+ datasets to AWS Redshift, achieving 40% cost savings',
                'Managed full-stack development, reducing cycle time by 30% through efficient requirements',
                'Designed and implemented data lakes and centralized data warehouses on Hadoop',
                'Conducted advanced data analysis and optimized SQL queries on Oracle and Redshift',
                'Developed Power BI dashboards and generated monthly and weekly reports using DAX',
                'Utilized DAX and MDX in Tabular Mode and multi-dimensional Cubes for complex calculations'
            ]
        },
        {
            'position': 'Data Analyst Intern',
            'company': 'KPMG International Limited',
            'location': 'Remote',
            'dates': 'Aug 2021 – Nov 2021',
            'responsibilities': [
                'Developed interactive dashboards and reports using Tableau Desktop',
                'Transitioned SQL Server objects to Snowflake DB',
                'Created advanced Tableau scorecards and dashboards with heatmaps',
                'Optimized SQL queries, reducing processing time by 30%'
            ]
        },
        {
            'position': 'Data Analyst Intern',
            'company': 'Standard bank',
            'location': 'Remote',
            'dates': 'Dec 2021 – Feb 2022',
            'responsibilities': [
                'Utilized statistical software like Python to collect and analyze extensive datasets',
                'Developed and maintained data visualizations such as dashboards',
                'Adhered to data governance policies to ensure data accuracy',
                'Maintained up-to-date knowledge of latest data analysis techniques',
                'Handled large and intricate datasets using specialized skills and tools'
            ]
        }
    ]

    # Display Resume
    print(f"\n{contact_info['Name']}\n")
    print(f"{contact_info['Mobile']} | {contact_info['Email']} | {contact_info['LinkedIn']}\n")
    
    print("EDUCATION")
    for edu in education:
        print(f"{edu['degree']}, {edu['university']}, {edu['location']}\t{edu['dates']}")
    
    print("\nSKILLS")
    for category, items in skills.items():
        print(f"• {category}: {', '.join(items)}")
    
    print("\nEXPERIENCE")
    for job in experience:
        print(f"\n{job['position']} | {job['company']} | {job['location']}\t{job['dates']}")
        for responsibility in job['responsibilities']:
            print(f"  • {responsibility}")

# Run the function to display resume
display_resume()